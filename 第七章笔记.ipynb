{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastbook import *\n"
   ]
  },
  {
   "source": [
    "# 协同过滤 collaborative filtering"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "协同过滤是一种在推荐系统中常用的方法，通过分析用户和项目之间的关系，来发现其他用户对于这种项目的潜在的兴趣，比如说在B站里面，你看了很多二次元动画片，b站就会给你推荐很多其他也喜欢看二次元动画片的人也喜欢看的东西。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "这次用的数据集是一个叫MovieLens的数据集，主要包含了电影的一些数据。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.collab import *\n",
    "from fastai.tabular.all import *\n",
    "path = untar_data(URLs.ML_100k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   user  movie  rating  timestamp\n",
       "0   196    242       3  881250949\n",
       "1   186    302       3  891717742\n",
       "2    22    377       1  878887116\n",
       "3   244     51       2  880606923\n",
       "4   166    346       1  886397596"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user</th>\n      <th>movie</th>\n      <th>rating</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>196</td>\n      <td>242</td>\n      <td>3</td>\n      <td>881250949</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>186</td>\n      <td>302</td>\n      <td>3</td>\n      <td>891717742</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>22</td>\n      <td>377</td>\n      <td>1</td>\n      <td>878887116</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>244</td>\n      <td>51</td>\n      <td>2</td>\n      <td>880606923</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>166</td>\n      <td>346</td>\n      <td>1</td>\n      <td>886397596</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "ratings = pd.read_csv(path/'u.data', delimiter='\\t', header=None,\n",
    "                      names=['user','movie','rating','timestamp'])\n",
    "ratings.head()"
   ]
  },
  {
   "source": [
    "这个数据集中有用户的编号，电影的编号，用户对于电影的评分，还有个时间戳\n",
    "\n",
    "## 目标函数的处理\n",
    "\n",
    "接下来，我们需要将电影的元素用一个向量来表示，比如第一个参数表示多大程度上是科幻片，第二个是动作电影的程度，第三个是这个电影是不是老电影，用一个（-1,1）的域来表示。比如这个《星战最后的绝地武士》这个电影（名字我猜的，我没看过），就是典型的科幻动作电影，但是不是老电影"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_skywalker = np.array([0.98,0.9,-0.9])"
   ]
  },
  {
   "source": [
    "相同的我们也可以将用户的属性来表示出来，比如这个用户比较喜欢动作和科幻电影，但是不喜欢老电影"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "user1 = np.array([0.9,0.8,-0.6])"
   ]
  },
  {
   "source": [
    "我们把这两个向量相乘,这个结果就是用户对于这个电影的喜欢程度\n",
    "\n",
    "PS:在pytorch和numpy中，点乘是*，叉乘是@"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2.1420000000000003"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "(user1*last_skywalker).sum()"
   ]
  },
  {
   "source": [
    "换个例子，这个卡萨布兰卡绝对不是一个科幻电影，动作成分也基本没有，但是是一个实打实的老电影，这样的电影碰上user1会如何呢？"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "casablanca = np.array([-0.99,-0.3,0.8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-1.611"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "(user1*casablanca).sum()"
   ]
  },
  {
   "source": [
    "结果上来讲是一个代表不喜欢的负值。\n",
    "\n",
    "OK,将这个特例拓展到整个样本空间，这样的话我们就能得到一个所有用户对于所有电影的喜好矩阵了。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 创建数据集"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   movie              title\n",
       "0      1   Toy Story (1995)\n",
       "1      2   GoldenEye (1995)\n",
       "2      3  Four Rooms (1995)\n",
       "3      4  Get Shorty (1995)\n",
       "4      5     Copycat (1995)"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>movie</th>\n      <th>title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Toy Story (1995)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>GoldenEye (1995)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Four Rooms (1995)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Get Shorty (1995)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Copycat (1995)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "movies = pd.read_csv(path/'u.item',  delimiter='|', encoding='latin-1',\n",
    "                     usecols=(0,1), names=('movie','title'), header=None)\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   user  movie  rating  timestamp         title\n",
       "0   196    242       3  881250949  Kolya (1996)\n",
       "1    63    242       3  875747190  Kolya (1996)\n",
       "2   226    242       5  883888671  Kolya (1996)\n",
       "3   154    242       3  879138235  Kolya (1996)\n",
       "4   306    242       5  876503793  Kolya (1996)"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user</th>\n      <th>movie</th>\n      <th>rating</th>\n      <th>timestamp</th>\n      <th>title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>196</td>\n      <td>242</td>\n      <td>3</td>\n      <td>881250949</td>\n      <td>Kolya (1996)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>63</td>\n      <td>242</td>\n      <td>3</td>\n      <td>875747190</td>\n      <td>Kolya (1996)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>226</td>\n      <td>242</td>\n      <td>5</td>\n      <td>883888671</td>\n      <td>Kolya (1996)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>154</td>\n      <td>242</td>\n      <td>3</td>\n      <td>879138235</td>\n      <td>Kolya (1996)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>306</td>\n      <td>242</td>\n      <td>5</td>\n      <td>876503793</td>\n      <td>Kolya (1996)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "ratings = ratings.merge(movies)\n",
    "ratings.head()"
   ]
  },
  {
   "source": [
    "pd有个特点就是能够进行和sql一样的联表操作，这两个表都有带一个movie字段，所以能够进行联表操作.\n",
    "\n",
    "创建数据集的时候我们需要创建一个协同的数据集，调用`CollabDataLoaders`这个类中的从dataframe创建数据集的函数`from_df`，数据来源是ratings，需要进行分析的item是title这一列的数据，如果这一列的字段名是item就不用单独设置了，如果数据集中的rating不是这个名字的话，也需要有个参数名字是rating_name来设置"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user</th>\n      <th>title</th>\n      <th>rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>542</td>\n      <td>My Left Foot (1989)</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>422</td>\n      <td>Event Horizon (1997)</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>311</td>\n      <td>African Queen, The (1951)</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>595</td>\n      <td>Face/Off (1997)</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>617</td>\n      <td>Evil Dead II (1987)</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>158</td>\n      <td>Jurassic Park (1993)</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "dls = CollabDataLoaders.from_df(ratings, item_name='title', bs=6,num_workers=0)\n",
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users  = len(dls.classes['user'])\n",
    "n_movies = len(dls.classes['title'])\n",
    "n_factors = 5\n",
    "\n",
    "user_factors = torch.randn(n_users, n_factors)\n",
    "movie_factors = torch.randn(n_movies, n_factors)"
   ]
  },
  {
   "source": [
    "`n_users`和`n_movies`这两个变量是存放用户的数量和电影的数量的，同时`n_factors`说明有5个评判维度,用一张图说明一下"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<img alt=\"Latent factors with crosstab\" width=\"900\" caption=\"Latent factors with crosstab\" id=\"xtab_latent\" src=\"images/att_00041.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "这个橙色的框中就是用户有的五个偏好向量，同样淡蓝色的框中也是电影所有的偏好向量，将这两个矩阵相乘，得到的就是白色部分的用户对于该电影的喜好程度了.\n",
    "\n",
    "但是这又引申出来一个问题：如何得到特定用户对于特定电影的喜好程度？ 这就需要在这样的表中使用索引的查找内容。深度学习中并不包含这样的内容，但是我们可以用矩阵的乘法来表示出来，要用到独热编码。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "one_hot_3 = one_hot(3, n_users).float()     \n",
    "one_hot_3"
   ]
  },
  {
   "source": [
    "将用户集中的所有用户都使用独热编码进行编码，比如例子里面的将第三个用户用独热编码编码后得出一个（1，944）大小的矩阵，然后矩阵的第三个元素的值为1，其余全为0，将其与用户喜好的矩阵进行相乘，就能单独得到第三行的用户喜好矩阵（5，944），而且除了第三行元素外其他元素全部为0,这种方式称为embedding。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([-0.4586, -0.9915, -0.4052, -0.3621, -0.5908])"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "user_factors.t()@one_hot_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([6, 2])"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "x,y = dls.one_batch()\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotProduct(Module):\n",
    "    def __init__(self, n_users, n_movies, n_factors):\n",
    "        self.user_factors = Embedding(n_users, n_factors)\n",
    "        self.movie_factors = Embedding(n_movies, n_factors)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        users = self.user_factors(x[:,0])\n",
    "        movies = self.movie_factors(x[:,1])\n",
    "        return (users * movies).sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DotProduct(n_users, n_movies, 50)\n",
    "learn = Learner(dls, model, loss_func=MSELossFlat())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>1.584202</td>\n      <td>1.539200</td>\n      <td>01:40</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>1.303441</td>\n      <td>1.517572</td>\n      <td>01:43</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.036151</td>\n      <td>1.223593</td>\n      <td>01:40</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.897574</td>\n      <td>0.980512</td>\n      <td>01:41</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.848717</td>\n      <td>0.925403</td>\n      <td>01:39</td>\n    </tr>\n  </tbody>\n</table>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "learn.fit_one_cycle(5,5e-3)"
   ]
  },
  {
   "source": [
    "这样一个基本的模型就做好了，但是我们还是要考虑一个问题，如果有用户习惯性的给一个电影打高分or低分，碰上一个大家都觉得不错的电影，这样这个推荐算法就不是很有效果了，这时候我们要考虑到所谓的偏差。下面是改进后的模型。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotProductBias(Module):\n",
    "    def __init__(self, n_users, n_movies, n_factors, y_range=(0,5.5)):\n",
    "        self.user_factors = Embedding(n_users, n_factors)\n",
    "        self.user_bias = Embedding(n_users, 1)              #用户的偏差\n",
    "        self.movie_factors = Embedding(n_movies, n_factors)\n",
    "        self.movie_bias = Embedding(n_movies, 1)            #电影的偏差\n",
    "        self.y_range = y_range\n",
    "        \n",
    "    def forward(self, x):\n",
    "        users = self.user_factors(x[:,0])\n",
    "        movies = self.movie_factors(x[:,1])\n",
    "        res = (users * movies).sum(dim=1, keepdim=True)\n",
    "        res += self.user_bias(x[:,0]) + self.movie_bias(x[:,1])\n",
    "        return sigmoid_range(res, *self.y_range)"
   ]
  },
  {
   "source": [
    "给每个电影和用户加一个偏差变量，这个user_bias和movie_bias就是偏差量，并嵌入到矩阵中，"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.960878</td>\n      <td>0.983803</td>\n      <td>01:55</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.869596</td>\n      <td>0.974227</td>\n      <td>02:16</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.774579</td>\n      <td>0.935645</td>\n      <td>01:49</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.493746</td>\n      <td>0.921011</td>\n      <td>01:54</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.376816</td>\n      <td>0.925238</td>\n      <td>01:59</td>\n    </tr>\n  </tbody>\n</table>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "model = DotProductBias(n_users, n_movies, 50)\n",
    "learn = Learner(dls, model, loss_func=MSELossFlat())\n",
    "learn.fit_one_cycle(5, 5e-3)"
   ]
  },
  {
   "source": [
    "效果不好，loss是下降的，原因是出现了过拟合。解决方式是使用正则化先处理数据。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 正则化"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "要避免过拟合，一个办法就是减少模型中变量的数量，但是在实际的操作中很少有这么做，而是将变量变的很小，这里用到的技术是权重衰减（weight decay）也被叫做L2正则化，虽然有一点点不同，但是基本可以认为是一种方法。\n",
    "\n",
    "``` python\n",
    "loss_with_wd = loss + wd * (parameters**2).sum()\n",
    "```\n",
    "\n",
    "这里的wd就是所谓的权重缩减，最初我们的想法是减少变量的数量来达到降低模型复杂度的效果，但是这个问题是一个NP问题，也就是我们需要花很多时间去解决的问题，于是退而求其次，将模型中的变量尽量接近0，以达到减少变量的近似效果。\n",
    "\n",
    "对于上式的参数求导后，就可以得到梯度的一个关系\n",
    "\n",
    "``` python\n",
    "parameters.grad += wd * 2 * parameters\n",
    "```\n",
    "\n",
    "\n",
    "在fastai中使用正则化的方式是在调用fit_one_cycle()函数中加入参数wd"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>1.232177</td>\n      <td>1.081926</td>\n      <td>01:59</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>1.000025</td>\n      <td>1.055134</td>\n      <td>01:50</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.008135</td>\n      <td>0.992293</td>\n      <td>01:46</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.002289</td>\n      <td>0.936471</td>\n      <td>01:48</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.922965</td>\n      <td>0.915843</td>\n      <td>01:42</td>\n    </tr>\n  </tbody>\n</table>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "model = DotProductBias(n_users, n_movies, 50)\n",
    "learn = Learner(dls, model, loss_func=MSELossFlat())\n",
    "learn.fit_one_cycle(5, 5e-3, wd=0.1)                    #正则化大小为0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleAttributeError",
     "evalue": "'Embedding' object has no attribute 'squeeze'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleAttributeError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-8ae750737ef5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmovie_bias\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmovie_bias\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0midxs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmovie_bias\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'title'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0midxs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 778\u001b[1;33m         raise ModuleAttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[0;32m    779\u001b[0m             type(self).__name__, name))\n\u001b[0;32m    780\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleAttributeError\u001b[0m: 'Embedding' object has no attribute 'squeeze'"
     ]
    }
   ],
   "source": [
    "movie_bias = learn.model.movie_bias.squeeze()\n",
    "idxs = movie_bias.argsort()[:5]\n",
    "[dls.classes['title'][i] for i in idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}